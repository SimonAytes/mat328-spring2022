{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 15 - Logistic Regression Continued and Assessing Classification\n",
    "\n",
    "The Akimel O'odham people, who were also known as the Pima Indians since European colonization of the US, currently have a high prevalence of diabetes.   The Pima Indian Diabetes dataset contains different possible diabetes indicators and whether the person has diabetes is on [Kaggle](ttps://www.kaggle.com/uciml/pima-indians-diabetes-database) or available from [https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv](https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv)\n",
    "\n",
    "In this lab, we will look at some futher ways to asses how well a classification method is doing, and learn how to perform logistic regression with multiple input variables.\n",
    "\n",
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.special import expit\n",
    "from scipy.stats import logistic\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Loading the data and logistic regression on one variable\n",
    "\n",
    "This section will repeat the logistic regression from Lab 14 that predicted incidence of diabetes from the results of the 2 hour glucose test.\n",
    "\n",
    "Load the dataset into a dataframe called `diabetes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(\"https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a scatter plot of the 2-hour glucose measurement (x) vs. the diabetes outcome (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Glucose', ylabel='Outcome'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(diabetes['Glucose'], diabetes[\"Outcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a logistic regression model to this data, using Glucose as the independent variable and Outcome as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.526510\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Outcome</td>     <th>  No. Observations:  </th>  <td>   768</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   766</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Apr 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.1860</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>22:26:36</td>     <th>  Log-Likelihood:    </th> <td> -404.36</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -496.74</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.418e-42</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -5.3501</td> <td>    0.421</td> <td>  -12.713</td> <td> 0.000</td> <td>   -6.175</td> <td>   -4.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Glucose</th>   <td>    0.0379</td> <td>    0.003</td> <td>   11.647</td> <td> 0.000</td> <td>    0.031</td> <td>    0.044</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                Outcome   No. Observations:                  768\n",
       "Model:                          Logit   Df Residuals:                      766\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Tue, 05 Apr 2022   Pseudo R-squ.:                  0.1860\n",
       "Time:                        22:26:36   Log-Likelihood:                -404.36\n",
       "converged:                       True   LL-Null:                       -496.74\n",
       "Covariance Type:            nonrobust   LLR p-value:                 4.418e-42\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -5.3501      0.421    -12.713      0.000      -6.175      -4.525\n",
       "Glucose        0.0379      0.003     11.647      0.000       0.031       0.044\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model = smf.logit('Outcome ~ Glucose',diabetes).fit()\n",
    "logit_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assess this model by computing the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[443.,  57.],\n",
       "       [138., 130.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.pred_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of errors are most likely?\n",
    "\n",
    "### Section 2: Accuracy, Sensitivity, Specificty, and Precision\n",
    "\n",
    "Recall that the confusion matrix producted by the statsmodel logistic regression is\n",
    "\n",
    "<code>   \n",
    "                        predicted\n",
    "             |    0           |      1      |\n",
    "             --------------------------------\n",
    "observed | 0 | true negative  | false positive\n",
    "         | 1 | false negative | true positive\n",
    "</code>\n",
    "\n",
    "First let's extract the true and false positive and negative values from the confusion matrix and store them in variables so that we can use them in computations.\n",
    "\n",
    "We will store our confusion matrix in the variable `confusion_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[443.,  57.],\n",
       "       [138., 130.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = logit_model.pred_table()\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gives the values in the upper-left, upper-right, lower-left, and lower-right, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 0 and 1's in the [] actually refer to the row and column numbers, not the values being predicted.  The top row of the confusion matrix is row 0, and the left-most column is column 0.  \n",
    "\n",
    "Let's store these values in variables, to make them easier to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = confusion_matrix[0][0]\n",
    "false_pos = confusion_matrix[1][0]\n",
    "false_neg = confusion_matrix[0][1]\n",
    "true_neg = confusion_matrix[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2.1 Accuracy\n",
    "\n",
    "The *accuracy* of a classification model is proportion of data computed correctly:\n",
    "\n",
    "$\\text{accuracy} = \\frac{\\text{# of true positives + # of true negatives}}{\\text{# of data points}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74609375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (true_pos + true_neg)/len(diabetes)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the accuracy for this classification model?  Is it what you expected?  \n",
    "\n",
    "Accuracy can be misleading, especially when the number of data points in each category is unbalanced.  For example, if 90% of your data has category 0 and 10% has category 1, then we can get 90% accuracy by always predicting 0.  But this prediction would be useless. \n",
    "\n",
    "#### Section 2.2 Sensitivity\n",
    "\n",
    "*Sensitivity* or the *true positive rate* is the proportion of data belonging to the positive class that is classified correctly.\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{sensitivity} &= \\frac{\\text{# of true positives}}{\\text{# of actual positives}} \\\\\n",
    "&= \\frac{\\text{# of true positives}}{\\text{# of true positives + # of false negatives}}\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = true_pos/(true_pos + false_neg)\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the sensitivity of our model?  This is the proportion of people with diabetes who are identified correctly as having it.  A test that identifies if someone has a disease should have a very high sensitivity, because we want people who have the disease to test positive.\n",
    "\n",
    "#### Section 2.3 Specificity\n",
    "\n",
    "*Specificity* or the *true negative rate* is the proportion of data belonging to the negative class that is classified correctly.  \n",
    "\n",
    "$\\begin{align}\n",
    "\\text{specificity} &= \\frac{\\text{# of true negatives}}{\\text{# of actual negatives}} \\\\\n",
    "&= \\frac{\\text{# of true negatives}}{\\text{# of true negatives + # of false positives}}\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48507462686567165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity = true_neg/(true_neg + false_pos)\n",
    "specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the specificity of our model?  This is the proportion of people without diabetes who are identified correctly as not having diabetes.  \n",
    "\n",
    "The specificity of our model is less than 50%, so our model will predict that a lot of people without diabetes have it.  If specificity is low for a test for a disease, it may not be as bad as a low sensitivity (missing finding the disease in people who have it), but it is still a problem as a positive test result would be stressful and would require more testing to realize the test was wrong.\n",
    "\n",
    "However, there are situations where a high specificity is more important than a high sensitivity.  For example, if someone is innocent of a crime (\"negative\") it is more important that they are found innocent in a trial, than that a guilty person (\"positive\") is found guilty.\n",
    "\n",
    "#### Section 2.4: Precision\n",
    "\n",
    "*Precision* is the proportion of positive predictions that are actual positives.\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{precision} &= \\frac{\\text{# of true positives}}{\\text{# of predicted positives}} \\\\\n",
    "&= \\frac{\\text{# of true positives}}{\\text{# of true positives + # of false positives}}\n",
    "\\end{align}$\n",
    "\n",
    "Precision is an important metric for search engines, like Google.  The webpages suggested by Google in response to your search are its positive predictions, and we want as many of them to be relevant (true positives) as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7624784853700516"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = true_pos/(true_pos + false_pos)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the precision of our model?\n",
    "\n",
    "### Section 3: Logistic regression cut-off\n",
    "\n",
    "By default the confusion matrix uses 0.5 as the cut-off for whether a y value indicates 0  or 1.  We can change that by passing in the new cut-off as a parameter.  For example, to interpret values >= 0.7 as 1 and < 0.7 as 0, use the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[484.,  16.],\n",
       "       [195.,  73.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = logit_model.pred_table(0.7)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the confusion matrix change?  Do you think this new model is better or worse?  Recompute the sensitivity and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the sensitivity and specificity change?  Are they better or worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Logistic Regression with Multiple Independent Variables\n",
    "\n",
    "Let's compute a logistic regression model using all of the columns in the `diabetes` DataFrame except `Outcome` as independent variables.  Can you figure out how to do this with statsmodels? \n",
    "\n",
    "Hint:  The command is similar to multi-variable linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.470993\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Outcome</td>     <th>  No. Observations:  </th>  <td>   768</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   759</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Apr 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.2718</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>22:38:18</td>     <th>  Log-Likelihood:    </th> <td> -361.72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -496.74</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>9.652e-54</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>   -8.4047</td> <td>    0.717</td> <td>  -11.728</td> <td> 0.000</td> <td>   -9.809</td> <td>   -7.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pregnancies</th>              <td>    0.1232</td> <td>    0.032</td> <td>    3.840</td> <td> 0.000</td> <td>    0.060</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Glucose</th>                  <td>    0.0352</td> <td>    0.004</td> <td>    9.481</td> <td> 0.000</td> <td>    0.028</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BloodPressure</th>            <td>   -0.0133</td> <td>    0.005</td> <td>   -2.540</td> <td> 0.011</td> <td>   -0.024</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SkinThickness</th>            <td>    0.0006</td> <td>    0.007</td> <td>    0.090</td> <td> 0.929</td> <td>   -0.013</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Insulin</th>                  <td>   -0.0012</td> <td>    0.001</td> <td>   -1.322</td> <td> 0.186</td> <td>   -0.003</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>                      <td>    0.0897</td> <td>    0.015</td> <td>    5.945</td> <td> 0.000</td> <td>    0.060</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DiabetesPedigreeFunction</th> <td>    0.9452</td> <td>    0.299</td> <td>    3.160</td> <td> 0.002</td> <td>    0.359</td> <td>    1.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>                      <td>    0.0149</td> <td>    0.009</td> <td>    1.593</td> <td> 0.111</td> <td>   -0.003</td> <td>    0.033</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                Outcome   No. Observations:                  768\n",
       "Model:                          Logit   Df Residuals:                      759\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Tue, 05 Apr 2022   Pseudo R-squ.:                  0.2718\n",
       "Time:                        22:38:18   Log-Likelihood:                -361.72\n",
       "converged:                       True   LL-Null:                       -496.74\n",
       "Covariance Type:            nonrobust   LLR p-value:                 9.652e-54\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                   -8.4047      0.717    -11.728      0.000      -9.809      -7.000\n",
       "Pregnancies                  0.1232      0.032      3.840      0.000       0.060       0.186\n",
       "Glucose                      0.0352      0.004      9.481      0.000       0.028       0.042\n",
       "BloodPressure               -0.0133      0.005     -2.540      0.011      -0.024      -0.003\n",
       "SkinThickness                0.0006      0.007      0.090      0.929      -0.013       0.014\n",
       "Insulin                     -0.0012      0.001     -1.322      0.186      -0.003       0.001\n",
       "BMI                          0.0897      0.015      5.945      0.000       0.060       0.119\n",
       "DiabetesPedigreeFunction     0.9452      0.299      3.160      0.002       0.359       1.531\n",
       "Age                          0.0149      0.009      1.593      0.111      -0.003       0.033\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model2 = smf.logit(\"Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age\", diabetes).fit()\n",
    "logit_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer:</summary>\n",
    "<code>\n",
    "logit_model2 = smf.logit(\"Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age\", diabetes).fit()\n",
    "logit_model2.summary()\n",
    "</code>\n",
    "</details>\n",
    "\n",
    "What is the pseudo R-squared value for this model? Is it an improvement on the model with only `Glucose` as the independent variable?\n",
    "\n",
    "As with linear regression, we should also look at the p-values of the independent variables.  Are any of the p-values greater than 0.05?  If so, let's create a new logistic regression model without those columns, as they likely do not affect the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[478.,  22.],\n",
       "       [168., 100.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model2.pred_table(0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the equation for this logistic regression model?\n",
    "\n",
    "$y = \\frac{1}{1 + e^{-(-7.9550 + 0.1535x_1 + 0.0347x_2 + -0.0120x_3 + 0.0848x_4 + 00.9106x_5)}}$\n",
    "where $x_1$ is the pregnancies variable, $x_2$ is the glucose variable, $x_3$ is the blood pressure variable, $x_4$ is the BMI variable and $x_5$ is the DiabetesPedigreeFunction variable\n",
    "\n",
    "Compute the confusion matrix for this logistic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think this is an improvement over the model based only on glucose?\n",
    "\n",
    "Compute the sensitivity and specificity for the new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the sensitivity and specificity compare to the simpler model?  Play around with the cut-off to see what number gives the best results.\n",
    "\n",
    "### Challenges\n",
    "- To better understand the data, plot the distributions of the Glucose column for people with diabetes and without diabetes as overlapping histograms.  How does this graph compare to the scatterplot of glucose vs. outcome?  Which gives more information?\n",
    "- (Very challenging) A *Receiver Operating Characteristic curve* or *ROC curve* gives information about the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity) as the cut-off changes.  To plot such a curve, use a loop to compute the true positive rate and false positive rate for multiple cut-offs (eg. 0.1, 0.2, ..., 0.8, 0.9), and plot a line plot of these values with the false positive rate on the x axis and the true positive rate on the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
