{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace with your name and a brief description of the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 16\n",
    "\n",
    "This homework uses the Pima Indian Diabetes dataset from Labs 14 and 15.  We will use decision trees and random forests to try to predict whether or not a person has diabetes.\n",
    "\n",
    "Data URL:  [https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv]( https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Loading and preparing the data\n",
    "\n",
    "a) Load the data into your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(\"https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b) Split the data into a DataFrame called `x` that contains all columns except `Outcome` (the independent variables), and a Series called `y` that contains the `Outcome` column (the dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = diabetes.drop(columns=[\"Outcome\"])\n",
    "y = diabetes[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1c) Split your `x` and `y` variables from 1b into training (80%) and testing (20%) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Decision tree with max depth 5\n",
    "\n",
    "2a) Fit a decision tree with max depth 5 to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth = 5)\n",
    "dt_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b) Use your decision tree from 2a to predict `Outcome` for your testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_y_pred_test = dt_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2c) Compute the confusion matrix for your predictions.  How does it compare to the confusion matrix from Lab 15, Section 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85,  6],\n",
       "       [27, 36]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, dt_y_pred_test)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d) How does this confusion matrix compare to the confusion matrix from Lab 15, Section 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d answer:** They both have a sizeable type II error rate, but all in all this model performed better as it's share of errors was less (~30%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2e) Compute the sensitivity and specificity of your decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = conf_mat[0][0]\n",
    "false_pos = conf_mat[1][0]\n",
    "false_neg = conf_mat[0][1]\n",
    "true_neg = conf_mat[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.9340659340659341\n",
      "Specificity: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "sensitivity = true_pos/(true_pos + false_neg)\n",
    "specificity = true_neg/(true_neg + false_pos)\n",
    "print(f\"Sensitivity: {sensitivity}\\nSpecificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2f) Based on 2e, does this model do a better job predicting that people have diabetes or don't have it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f answer:** According to these scores, it is not good at predicting whether or not people have diabetes. Its sensitivity indicates a high type II error rate, and its specificity indicates a moderate type I error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Testing other parameters for the decision tree\n",
    "\n",
    "a) Fit a decision tree with a different max depths on the training data, and use it to make predictions for the testing data.  Compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2_model = DecisionTreeClassifier(max_depth = 10)\n",
    "dt2_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_y_pred_test2 = dt2_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75, 16],\n",
       "       [22, 41]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat2 = confusion_matrix(y_test, dt_y_pred_test2)\n",
    "conf_mat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3b) Fit a decision tree with a different max depth than in question 2 or 3a on the training data, and use it to make predictions for the testing data.  Compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3_model = DecisionTreeClassifier(max_depth = 2)\n",
    "dt3_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_y_pred_test3 = dt3_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88,  3],\n",
       "       [36, 27]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat3 = confusion_matrix(y_test, dt_y_pred_test3)\n",
    "conf_mat3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3c) Of the three decision tree depths you have tested (Questions 2, 3a, 3b), which would you recommend for predicting diabetes?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c answer:** Based solely off of the confusion matrices, I would choose the first one with a depth of 5. This is because between all three it had the highest number of correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Random forest\n",
    "\n",
    "a) Fit a random forest with 500 estimators (random decision trees) of max depth 10 to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500, max_depth = 10)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4b) Use the random forest trained in 4a to predict the `Outcome` variable for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds_rf = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4c) Compute the confusion matrix for your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[84,  7],\n",
       "       [21, 42]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat1 = confusion_matrix(y_test,y_test_preds_rf)\n",
    "conf_mat1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4d) How does it compare to the confusion matrix from Lab 15, Section 4, and the best confusion matrix from Question 3c?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d answer:** It has a better TP and TN rate, which is good. But it still has a noticeable type I error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4e) Compute the sensitivity and specificity of your random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos1 = conf_mat1[0][0]\n",
    "false_pos1 = conf_mat1[1][0]\n",
    "false_neg1 = conf_mat1[0][1]\n",
    "true_neg1 = conf_mat1[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.9230769230769231\n",
      "Specificity: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "sensitivity1 = true_pos1/(true_pos1 + false_neg1)\n",
    "specificity1 = true_neg1/(true_neg1 + false_pos1)\n",
    "print(f\"Sensitivity: {sensitivity1}\\nSpecificity: {specificity1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4f) Does the model do a better job predicting that people have diabetes or don't have it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4f answer:** It's sensitivity is slightly lower than that of the decision tree's, but its specificity is higher by ~0.2. Overall, it is not better than the decision tree at predicting whether someone has diabetes or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Testing other parameters for the random forest model\n",
    "\n",
    "a) Fit another random forest with different parameters (number of estimators and max depth) on the training data, and use it to predict the variable `Outcome` for the testing data.  Compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, n_estimators=1000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators = 1000, max_depth = 15)\n",
    "rf1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds_rf1 = rf1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81, 10],\n",
       "       [22, 41]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat2 = confusion_matrix(y_test,y_test_preds_rf1)\n",
    "conf_mat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5b) Fit a third random forest with different parameters (number of estimators and max depth) on the training data, and use it to predict the variable `Outcome` for the testing data.  Compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators = 300, max_depth = 5)\n",
    "rf2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds_rf2 = rf2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85,  6],\n",
       "       [26, 37]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat3 = confusion_matrix(y_test,y_test_preds_rf2)\n",
    "conf_mat3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5c) Of the three random forests you tested (Question 4, 5a, 5b), which would you recommend for predicting diabetes?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5c answer:**  I would reccomend the third one because it made the most correct predictions and had the least type II error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5d) Of the logistic regression model from Lab 15, Section 4, the best decision tree from Question 3c, and the best random forest from Question 5c, which model would you use to predict diabetes?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5d answer:** I would reccomend the last random forest model tested in this homework (referenced in 5C) because of its lower FN / FP error rates. Especially with diabetes, a lower type II error rate is very important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
