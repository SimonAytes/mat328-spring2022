{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace with your name and a brief description of the notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv# Homework 17\n",
    "\n",
    "This homework uses the Pima Indian Diabetes dataset from Labs 14 and 15.  We will use decision trees and random forests to try to predict whether or not a person has diabetes.\n",
    "\n",
    "Data URL:  [https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv]( https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Loading and preparing the data\n",
    "\n",
    "a) Load the data in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(\"https://raw.githubusercontent.com/megan-owen/MAT328-Techniques_in_Data_Science/main/data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b) Create a DataFrame called `x` that contains all columns except `Outcome` (the independent variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = diabetes.drop(columns=[\"Outcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1c) Create a Series called `y` that contains the `Outcome` column (the dependent variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d) Split variables `x` and `y` into training (80%) and testing (20%) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: K-Nearest Neighbors Classifier\n",
    "\n",
    "2a) Fit a k-nearest neighbors classifer with k=5 to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn5.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b) Use your classifier from 2a to predict the outcome for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = knn5.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2c) Compute the confusion matrix for your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88, 11],\n",
       "       [25, 30]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_test_preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d) How many true positives and true negatives are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d answer:** There are 30 true positives and 88 true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2e) Compute the sensitivity and specificity of this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = cm[1,1]\n",
    "false_pos = cm[1,0]\n",
    "false_neg = cm[0,1]\n",
    "true_neg = cm[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7317073170731707\n",
      "Specificity: 0.7787610619469026\n"
     ]
    }
   ],
   "source": [
    "sensitivity = true_pos/(true_pos + false_neg)\n",
    "specificity = true_neg/(true_neg + false_pos)\n",
    "\n",
    "print(f\"Sensitivity: {sensitivity}\\nSpecificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2f) Does the model do a better job predicting that people have diabetes or don't have it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f answer:** It is pretty bad at both, thought it is slightly worse at predicting that people have it. The false negative error rate is higher than the false positive rate, but only by about `0.04`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Testing a different parameter\n",
    "\n",
    "a) Fit a second k-nearest neighbor classifier to the training data with a different k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn10 = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn10.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3b) Use your classifier from 3a to predict the outcome for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = knn10.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3c) Compute the confusion matrix, sensitivity, and specificity for your predictions from 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90  9]\n",
      " [27 28]]\n",
      "Sensitivity: 0.7567567567567568\n",
      "Specificity: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_test_preds)\n",
    "print(cm)\n",
    "true_pos = cm[1,1]\n",
    "false_pos = cm[1,0]\n",
    "false_neg = cm[0,1]\n",
    "true_neg = cm[0,0]\n",
    "sensitivity = true_pos/(true_pos + false_neg)\n",
    "specificity = true_neg/(true_neg + false_pos)\n",
    "print(f\"Sensitivity: {sensitivity}\\nSpecificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3d) Is this model better or worse than the model with k = 5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d answer:** This model is worse than the model with k = 5 because both error rates are higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Testing a third parameter\n",
    "\n",
    "a) Fit a third k-nearest neighbor classifier to the training data with a different k than 5 or the one used in Question 3.\n",
    ", and use it to make predictions for the testing data. Compute the confusion matrix, sensitivity, and specificity. Is this model better or worse than the previous two k-nearest neighbor classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors = 2)\n",
    "knn2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4b) Use your classifier from 4a to predict the outcome for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = knn2.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4c) Compute the confusion matrix, sensitivity, and specificity for your predictions from 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93  6]\n",
      " [33 22]]\n",
      "Sensitivity: 0.7857142857142857\n",
      "Specificity: 0.7380952380952381\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_test_preds)\n",
    "print(cm)\n",
    "true_pos = cm[1,1]\n",
    "false_pos = cm[1,0]\n",
    "false_neg = cm[0,1]\n",
    "true_neg = cm[0,0]\n",
    "sensitivity = true_pos/(true_pos + false_neg)\n",
    "specificity = true_neg/(true_neg + false_pos)\n",
    "print(f\"Sensitivity: {sensitivity}\\nSpecificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4d) Is this model better or worse than the previous two k-nearest neighbor classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d answer:** This model has a better false negative error rate than both of the previous models, however, it's false positive error rate is the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Comparison with other classifiers\n",
    "\n",
    "Compare your best k-nearest neighbor classifier with the best classifier from Homework 16, Question 5d.  Which model would you use to predict diabetes in someone?  Why?  (If you did not complete that question in Homework 16, use the Homework 16 solutions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5 answer:** Between the two, the kmeans classifier where k = 2 is better. The sensitivity of the one in HW 16 Q5d was about 0.86, and its specificity was arounf 0.75 -- both of which were higher than this kmeans model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
